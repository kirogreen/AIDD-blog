var relearn_searchindex = [
  {
    "breadcrumb": "Learn Latest AIDD",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Blogs",
    "uri": "/blog/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Categories",
    "uri": "/categories/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary Title: Protein Engineering for Thermostability through Deep Evolution\nJournal: bioRxiv (preprint)\nPublication Date: May 5, 2023\nDOI: https://doi.org/10.1101/2023.05.04.539497\nPrimary Research Institution: Tianjin Institute of Industrial Biotechnology, Chinese Academy of Sciences\nAbstract: This study presents DeepEvo, a deep learning-based strategy for engineering protein thermostability through iterative sequence generation and selection. The approach combines a Variant-generator (based on ProteinGAN) to create functional protein variants and a Thermo-selector (based on ESM protein language model) to identify thermostable sequences. Applied to glyceraldehyde-3-phosphate dehydrogenase (G3PDH), DeepEvo successfully generated highly thermostable variants with significantly improved efficiency compared to traditional directed evolution methods.\n2. Background The core scientific problem addressed is the inefficient and labor-intensive nature of traditional protein engineering for thermostability. Thermostable proteins are crucial for industrial applications in biocatalysis, biomedicine, and biomanufacturing, but conventional directed evolution requires multiple rounds of random mutagenesis and high-throughput screening. The main challenges include: the vastness of protein sequence space making exhaustive search impossible, the scarcity of functional sequences within this space, and the difficulty of combining multiple beneficial mutations without compromising protein function.\n3. Jargon Breakdown Deep Evolution (DeepEvo): A computational strategy that mimics natural evolution using deep learning models for iterative protein sequence generation and selection. It’s important because it enables more efficient exploration of functional sequence space compared to traditional methods.\nThermo-selector: A classifier model based on protein language embeddings that predicts whether a protein is high temperature tolerant (HTTP) or low temperature tolerant (LTTP). This is crucial for filtering generated sequences for thermostability without experimental testing.\nVariant-generator: A generative adversarial network (GAN) modified from ProteinGAN that produces novel but functional protein sequences. It’s important for creating diverse variants within constrained functional space.\nHTTP/LTTP: High/Low Temperature Tolerant Proteins, classified based on the optimal growth temperature of their source organisms (\u003e50°C or \u003c30°C respectively). This labeling enables supervised learning for thermostability prediction.\nESM embeddings: 1280-dimensional vector representations of protein sequences generated by the Evolutionary Scale Modeling language model. These embeddings capture evolutionary patterns and enable property prediction.\n4. Research Methodology The authors developed a two-model iterative framework:\nThermo-selector construction: Trained a classifier using ESM-1b embeddings of 193,858 proteins from organisms with known optimal growth temperatures to distinguish HTTPs from LTTPs (95.1% accuracy).\nVariant-generator development: Built a GAN-based model using 15,454 G3PDH sequences to generate functional variants while maintaining key conserved motifs.\nIterative DeepEvo process: Generated sequences with Variant-generator → filtered with Thermo-selector → used predicted HTTPs to retrain Variant-generator → repeated to enrich thermostable variants.\nExperimental validation: Synthesized and tested 30 generated G3PDH variants for expression, activity, and thermal stability.\n5. Innovations Key innovations include:\nIterative in silico evolution: Combining generation and selection in a closed-loop system that mimics natural evolution but in computational space Global sequence space exploration: Unlike directed evolution’s local search, DeepEvo explores broader functional sequence space Synergistic mutation clusters: The method naturally identifies coordinated mutation networks rather than isolated point mutations Property-driven generation: Directly optimizes for thermostability during sequence generation rather than post-hoc filtering 6. Applications Industrial enzyme engineering: Creating thermostable enzymes for high-temperature industrial processes (e.g., biofuel production, waste degradation) Therapeutic protein optimization: Engineering stable protein therapeutics and antibodies with improved shelf-life and stability Biocatalyst development: Generating thermostable enzymes for synthetic biology and biomanufacturing applications Research tool: Providing insights into thermostability mechanisms and protein sequence-stability relationships\nSpecific examples demonstrated include engineering thermostable variants of G3PDH (key glycolytic enzyme) and malate dehydrogenase, with potential applications in diagnostic kits and industrial biocatalysis.\n7. Limitations \u0026 Future Work Limitations acknowledged:\nDemonstrated primarily on two model enzymes; broader validation needed Dependency on quality and breadth of training data Limited to single-property optimization in current implementation Future directions suggested:\nExtend to multiple protein properties simultaneously (pH tolerance, substrate specificity) Incorporate structural information into the generation process Apply to other protein engineering challenges beyond thermostability Integrate with experimental high-throughput screening for hybrid approaches 8. Connections This work represents a significant advancement in AIDD by enabling new capabilities rather than incremental improvement. It bridges the gap between generative protein design and property-specific optimization, moving beyond traditional directed evolution’s limitations. DeepEvo demonstrates how AI can recapitulate evolutionary principles computationally, potentially revolutionizing protein engineering by making it possible to explore sequence spaces that are experimentally inaccessible. The method’s ability to identify synergistic mutation clusters addresses a fundamental challenge in protein engineering that has limited rational design approaches.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "Protein Engineering",
      "Thermostability",
      "Generative Models",
      "Protein Language Models",
      "Directed Evolution"
    ],
    "title": "Deep Evolution: AI-Driven Protein Thermostability Engineering",
    "uri": "/blog/20251011/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Directed Evolution",
    "uri": "/tags/directed-evolution/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Generative Models",
    "uri": "/tags/generative-models/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Categories",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Category :: Literature Review",
    "uri": "/categories/literature-review/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Protein Engineering",
    "uri": "/tags/protein-engineering/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Protein Language Models",
    "uri": "/tags/protein-language-models/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tags",
    "uri": "/tags/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Thermostability",
    "uri": "/tags/thermostability/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Antibody",
    "uri": "/tags/antibody/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Bayesian Flow Networks",
    "uri": "/tags/bayesian-flow-networks/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "Summary:\nTitle: Protein sequence modelling with Bayesian flow networks Journal: Nature Communications Publication Date: 03 April 2025 DOI: 10.1038/s41467-025-58250-2 Primary Research Institution: InstaDeep, London, England Abstract: This work introduces ProtBFN, a 650M parameter Bayesian Flow Network (BFN) model for protein sequence generation. Trained on curated UniProtKB sequences, it outperforms autoregressive (e.g., ProtGPT2) and discrete diffusion (e.g., EvoDiff) baselines in generating diverse, novel, and structurally coherent proteins. Fine-tuned on antibody heavy chains (AbBFN), it achieves competitive zero-shot conditional generation (e.g., CDR inpainting) compared to specialized BERT-style models, demonstrating BFNs’ flexibility for both unconditional and conditional tasks without task-specific training. Background: The vast combinatorial space of possible protein sequences remains largely unexplored, limiting our understanding of biology and hindering the design of novel therapeutic proteins. Machine learning, particularly methods inspired by natural language processing (NLP), has emerged as a key tool. However, prior state-of-the-art methods had significant limitations: autoregressive models (e.g., ProtGPT2) generate sequences left-to-right, which is ill-suited for proteins where functionally critical residues are dispersed throughout the sequence. Discrete diffusion models (e.g., EvoDiff) struggled to excel at both high-quality de novo (unconditional) generation and flexible conditional generation (e.g., inpainting) within a single framework. This work aims to solve the problem of creating a unified model capable of both tasks effectively.\nResearch Methodology: The authors employed Bayesian Flow Networks (BFNs), a generative framework that models the continuous parameters of a distribution over discrete data (amino acid sequences). The technical roadmap involved:\nTraining: Framed as a communication protocol where a “sender” (training data) sends progressively less noisy observations of a true sequence to a “receiver” (the neural network). The network (a 650M parameter transformer) learns to predict the parameters of the data distribution from these observations. Sampling: A continuous-time denoising process starts from a random prior and iteratively refines the distribution parameters to generate a novel sequence. Data: A curated dataset (UniProtCC) from UniProtKB, filtered for high-confidence protein existence. Model Variants: A general protein model (ProtBFN) was trained on UniProtCC. It was then fine-tuned on antibody heavy-chain sequences from the Observed Antibody Space (OAS) database to create AbBFN. Conditional Generation: For tasks like inpainting (e.g., predicting a missing CDR region), they used a Sequential Monte Carlo (SMC) sampling method on top of the unconditionally trained model, enabling zero-shot conditional generation. Innovations:\nUnified Framework: Demonstrates that BFNs can effectively handle both unconditional generation of novel protein sequences and arbitrary conditional generation (e.g., inpainting) within a single model, a key advantage over previous paradigms. Novel Sampling: Introduced a “Reconstructed ODE” (R-ODE) sampling method and “entropy encoding” (instead of time encoding) to stabilize generation and improve sample quality. Structural Coherence: Generated sequences show high predicted structural confidence (pLDDT) and diversity, covering a broader swath of known protein space (proteome coverage) than baselines while maintaining novelty (low sequence identity to training data). Zero-shot Conditional Capability: Shows that a model trained only for unconditional generation (AbBFN) can perform competitively on conditional tasks like antibody region inpainting without any task-specific training, challenging the need for specialized BERT-style models. Applications:\nDe Novo Protein Design: Generating entirely novel, functional protein sequences for therapeutic or enzymatic applications (e.g., novel enzymes, biosensors). Antibody Engineering: Specifically, the design of antibody variable regions. AbBFN can be used to: Generate novel, stable antibody heavy-chain candidates from scratch. “Fix” or redesign specific regions (e.g., CDRs for affinity maturation, frameworks for stability) of existing antibody sequences through inpainting. Exploring Protein Space: Systematically generating and studying proteins in uncharted regions of sequence space to uncover new folds and functions. Limitations \u0026 Future Work:\nLimitations: The authors note that BFNs are an emerging technology with fundamental questions remaining. AbBFN underperforms specialized models on the highly diverse CDR-H3 region prediction, likely due to the unique biological processes (V(D)J recombination) generating its diversity, which a general protein model may not capture perfectly. The sampling process sometimes generates low-quality sequences, necessitating a filtering step. Future Work: Suggested directions include extending BFNs to other biological sequences (RNA/DNA), developing multimodal BFNs that integrate sequence and structural data, and incorporating advanced sampling techniques from the diffusion literature to further improve performance. Jargon Breakdown:\nBayesian Flow Networks (BFNs): A class of generative models that learn a distribution over data by modeling continuous parameters of that distribution, rather than the data directly. This makes them naturally suited for discrete data like sequences. Importance: Provides a unified framework for generating and conditioning on discrete data. Example: ProtBFN uses BFNs to model the distribution of amino acids at each position in a protein. Inpainting: A conditional generation task where a model is given a partial sequence and must generate the missing parts. Importance: Critical for protein design, e.g., redesigning a specific loop while keeping the rest of the protein fixed. Example: Using AbBFN to generate a missing CDR-H3 sequence given the rest of an antibody chain. pLDDT (predicted Local Distance Difference Test): A per-residue confidence score (0-100) output by structure prediction models like AlphaFold or ESMFold. Higher scores indicate higher confidence in the predicted local structure. Importance: Used as a proxy metric for the structural plausibility and “foldability” of a generated protein sequence. Example: ProtBFN generates sequences with high mean pLDDT, suggesting they will fold into coherent structures. Unconditional vs. Conditional Generation: Unconditional generation means creating samples from the entire learned distribution (e.g., generating a random protein). Conditional generation means creating samples that satisfy given constraints (e.g., generating a protein that contains a specific motif). Importance: A model that excels at both is more flexible and powerful for design tasks. Sequential Monte Carlo (SMC): A sampling technique used for conditional generation with BFNs in this work. It uses multiple “particles” (guesses) that are resampled based on their agreement with the conditioning information. Importance: Enables the unconditionally trained BFN to perform complex conditional tasks like inpainting accurately. Connections: This paper represents a foundational advancement in the AIDD field, enabling a new capability rather than being an incremental improvement. It introduces a new model paradigm (BFNs) for biological sequences that challenges the dominance of autoregressive and diffusion models. Its key contribution is demonstrating that a single model architecture can achieve state-of-the-art performance in both unconditional generation and flexible conditional generation without task-specific training. This unification simplifies the model design process for protein engineers and opens new avenues for exploring sequence-structure-function relationships. It directly connects to and advances core AIDD themes like de novo protein design and antibody engineering.\nThe method presented in this paper has been open-sourced. Code is available at: https://github.com/instadeepai/protein-sequence-bfn",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "Protein Language Models",
      "De Novo Design",
      "Antibody",
      "Generative AI",
      "Bayesian Flow Networks"
    ],
    "title": "Bayesian Flow Networks Enable Unified Protein and Antibody Generation",
    "uri": "/blog/20251010/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: De Novo Design",
    "uri": "/tags/de-novo-design/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Generative AI",
    "uri": "/tags/generative-ai/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Biomedical Data Mining",
    "uri": "/tags/biomedical-data-mining/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Compressed Indexing",
    "uri": "/tags/compressed-indexing/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: De Bruijn Graphs",
    "uri": "/tags/de-bruijn-graphs/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Genomic Search",
    "uri": "/tags/genomic-search/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary Title: Efficient and accurate search in petabase-scale sequence repositories\nJournal: Nature\nPublication Date: 08 October 2025\nDOI: https://doi.org/10.1038/s41586-025-09603-w\nPrimary Research Institution: ETH Zurich, Switzerland\nAbstract: MetaGraph is a scalable framework for indexing and querying massive biological sequence datasets (DNA, RNA, proteins) using compressed annotated de Bruijn graphs. It enables cost-effective full-text search across 67 petabases of public sequencing data, achieving compression ratios up to 7,400× while supporting exact matching and sensitive alignment. The system democratizes access to entire sequence repositories, enabling discoveries in antibiotic resistance, phage biology, and circular RNA analysis.\n2. Background The exponential growth of public sequencing data (e.g., SRA/ENA archives now exceeding 67 petabases) has made traditional sequence search methods like BLAST impractical for repository-scale queries. Prior challenges included:\nStorage Inefficiency: Raw data requires petabytes of storage, limiting accessibility. Query Performance: Existing tools (BLAST, Mantis, COBS) either lacked scalability or sacrificed accuracy. Metadata Integration: Most methods couldn’t efficiently combine sequence search with sample-specific annotations (e.g., tissue type, geographic location).\nMetaGraph addresses the core problem of making petabase-scale biological sequences efficiently searchable by sequence content rather than just metadata. 3. Research Methodology The technical roadmap involves:\nGraph Construction: Convert raw sequences per sample into de Bruijn graphs (sample graphs) using k-mers (short k-length subsequences). Clean graphs to remove errors/contaminants via abundance-based filtering. Indexing: Merge sample graphs into a joint annotated de Bruijn graph (the “MetaGraph”). Compress the graph using succinct data structures (e.g., BOSS table) and annotations via sparse matrix compression (RowDiff, Multi-BRWT). Query Processing: Support both exact k-mer matching and sequence-to-graph alignment for sensitive searches. Use batch querying to exploit inter-query redundancy, accelerating throughput 32×. Scalability: Distribute indexes across cloud storage (e.g., AWS S3) and enable server-client querying via a Python API. 4. Innovations Lossless Compression at Scale: Achieves 300–7,400× compression while preserving annotations (e.g., sample IDs, k-mer counts), unlike lossy methods (COBS, kmindex). Unified Representation: Handles DNA, RNA, and protein sequences within the same framework. Alignment-Capable Indexing: First method to support both exact matching and sensitive graph-based alignment (via SCA/TCG-Aligner algorithms) at petabase scale. Cost-Efficiency: Reduces search costs to $0.74 per megabase for large queries, making global sequence search economically feasible. 5. Applications Antimicrobial Resistance (AMR) Tracking: Queried 241,384 gut microbiome samples against the CARD database to map global AMR gene spread and phage associations (Fig. 4a–b). Cancer Research: Detected back-splice junctions (circular RNAs) in TCGA/GTEx RNA-seq data, revealing tissue-specific patterns in cancers (e.g., esophageal carcinoma). Viral Discovery: Rapid screening of bacteriophages against metagenomic data to identify host–phage interactions. Drug Repurposing: Enables large-scale homology searches for protein targets across all publicly sequenced organisms. 6. Limitations \u0026 Future Work Limitations:\nLossy Cleaning: Filtering low-abundance k-mers may discard biologically relevant sequences. Static Indexes: Adding new samples requires full index reconstruction. Noisy Query Handling: Limited sensitivity for highly divergent sequences (e.g., nanopore data).\nFuture Directions: Dynamic index updates, support for epigenetic modifications (larger alphabets), and integration with machine learning for sequence generation. 7. Jargon Breakdown De Bruijn Graph: A graph where nodes represent k-mers, and edges represent overlaps of length k-1. Importance: Efficiently represents sequence sets by capturing all possible k-mers. Example: For sequences “ATG” and “TGC”, k-mers (k=2) are AT, TG, GC. k-mer: A contiguous subsequence of length k. Importance: Elementary unit for sequence comparison. Example: “GENOME” → k-mers (k=3): GEN, ENO, NOM, OME. Annotation Matrix: A sparse matrix linking k-mers to metadata (e.g., sample IDs). Importance: Enables querying sequences alongside biological context. RowDiff Compression: Encodes annotation differences between adjacent graph nodes. Importance: Reduces annotation storage by 10–100×. Sequence-to-Graph Alignment: Aligns query sequences to paths in the graph. Importance: Handles mutations/recombinations better than linear reference alignment. 8. Connections to AIDD MetaGraph is a capability-enabling tool for AIDD:\nIt provides a foundational infrastructure for large-scale in silico screening (e.g., searching entire sequence space for drug target homologs or antibody sequences). By compressing and indexing public data, it accelerates data retrieval for training AI models (e.g., protein language models). Not an incremental improvement but a paradigm shift: makes “Google for DNA” feasible, directly supporting drug discovery via rapid biodiversity mining. The method presented in this paper has been open-sourced. Code: GitHub. Data: AWS S3. Web service: MetaGraph Online.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "Genomic Search",
      "Compressed Indexing",
      "De Bruijn Graphs",
      "Sequence Alignment",
      "Biomedical Data Mining"
    ],
    "title": "MetaGraph: Google-Scale Search for Petabase Genomic Data",
    "uri": "/blog/20251009/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Sequence Alignment",
    "uri": "/tags/sequence-alignment/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary Title: One-shot design of functional protein binders with BindCraft\nJournal: Nature\nPublication Date: 27 August 2025\nDOI: https://doi.org/10.1038/s41586-025-09429-6\nPrimary Research Institution: École Polytechnique Fédérale de Lausanne (EPFL), Switzerland\nAbstract: This paper presents BindCraft, an open-source computational pipeline for de novo protein binder design that achieves experimental success rates of 10-100% across diverse targets. The method leverages AlphaFold2 weights to generate binders with nanomolar affinity without requiring high-throughput screening or known binding sites. The authors validated their approach against challenging targets including cell-surface receptors, allergens, de novo designed proteins, and CRISPR-Cas9, demonstrating therapeutic potential in reducing allergic responses, modulating gene editing, and enabling targeted gene delivery.\n2. Background Protein-protein interactions are fundamental to biological processes, but designing binders that specifically target these interactions has been challenging. Traditional methods like immunization, antibody library screening, and directed evolution are laborious, time-consuming, and offer limited control over target sites. Computational design approaches like Rosetta showed promise but suffered from low success rates (\u003c0.1%) and required extensive sampling. Recent deep learning advances, particularly AlphaFold2, revolutionized structure prediction but still left a gap between backbone generation and functional interface design. The core problem this work addresses is how to reliably design high-affinity protein binders computationally without requiring experimental optimization or prior knowledge of binding sites.\n3. Research Methodology The authors developed BindCraft as an automated pipeline that:\nUses ColabDesign implementation of AlphaFold2 to backpropagate through the network and hallucinate binder sequences Optimizes sequences through four stages: continuous space optimization, probability space optimization, straight-through estimator, and discrete one-hot encoding Applies MPNNsol for sequence optimization of binder core/surface while preserving interface residues Filters designs using AF2 monomer predictions, Rosetta physics-based scoring, and confidence metrics Tests top designs experimentally against 12 diverse targets Key technical aspects include target flexibility during design (unlike fixed-backbone methods), use of AF2 multimer for initial design followed by AF2 monomer for unbiased filtering, and automated workflow requiring minimal user intervention.\n4. Innovations Key innovations compared to previous methods:\nDirect AF2 backpropagation: Unlike RFdiffusion which generates backbones then designs sequences, BindCraft simultaneously optimizes structure, sequence, and interface Target flexibility: Allows binding-induced structural changes in both binder and target, unlike rigid-target approaches High success rates: 46.3% average experimental success rate vs. \u003c0.1% for physics-based methods and ~10% for RFdiffusion No binding site requirement: Successfully designs against targets without characterized binding sites Automated pipeline: Democratizes binder design for non-experts without computational expertise 5. Applications Specific real-world applications demonstrated:\nTherapeutics: Reduced IgE binding to birch allergen in patient-derived samples by up to 50% Gene editing modulation: Designed inhibitors of CRISPR-Cas9 that significantly reduced editing activity Toxin neutralization: Protected cells from bacterial enterotoxin cytotoxicity Targeted gene delivery: Engineered AAV capsids with miniprotein binders for cell-specific transduction Allergen masking: Designed binders against dust mite allergens Derf7 and Derf21 6. Limitations \u0026 Future Work Acknowledgements limitations:\nComputational intensity of AF2 backpropagation (GPU-intensive) AF2 monomer filtering may exclude some high-affinity binders AF2 insensitivity to point mutations could be problematic at interfaces i_pTM metric correlates with binding activity but not affinity Concerns about immunogenicity of synthetic binders remain Future directions suggested:\nIterative pipeline refinement toward “one design, one binder” ideal Addressing immunogenicity and delivery challenges Expanding to even more challenging targets Incorporating recent advances like AlphaFold3 7. Jargon Breakdown Hallucination: A computational technique where neural networks generate novel protein sequences and structures not found in nature by optimizing through the network weights. Important for creating entirely new binders.\ni_pTM (interface predicted TM-score): A confidence metric from AlphaFold that predicts the quality of protein-protein interfaces. Used in BindCraft to filter and rank designs.\nMPNNsol: A message-passing neural network variant optimized for designing soluble protein sequences. Used to improve expression and stability of designed binders.\nBackpropagation through AF2: The process of calculating gradients through the AlphaFold2 network to optimize input sequences for desired properties. Enables direct optimization of binding interfaces.\n8. Connections This paper represents a significant capability jump in AIDD rather than an incremental improvement. It enables:\nReliable de novo binder design without experimental screening Targeting previously “undruggable” interfaces like nucleic acid-binding sites Rapid development of therapeutic candidates and research tools Democratization of protein design to non-specialists The method has been open-sourced on GitHub at: https://github.com/martinpacesa/BindCraft\nThis work bridges the gap between computational prediction and experimental validation, moving the field closer to true “on-demand” protein design capabilities that could transform therapeutic development and biological research.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "De Novo Design",
      "Protein Binders",
      "AlphaFold",
      "Computational Biology",
      "Therapeutic Proteins"
    ],
    "title": "AI-Powered One-Shot Design of High-Affinity Protein Binders",
    "uri": "/blog/20251008/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: AlphaFold",
    "uri": "/tags/alphafold/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Computational Biology",
    "uri": "/tags/computational-biology/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Protein Binders",
    "uri": "/tags/protein-binders/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Therapeutic Proteins",
    "uri": "/tags/therapeutic-proteins/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary: Title: De novo design of RNA and nucleoprotein complexes\nJournal: bioRxiv (preprint)\nPublication Date: October 2, 2025\nDOI: https://doi.org/10.1101/2025.10.01.679929\nPrimary Research Institution: University of Washington, Institute for Protein Design\nAbstract: This study introduces RFDpoly, a generative diffusion framework for de novo design of RNA, DNA, and protein structures. The authors demonstrate the ability to design novel RNA folds and nucleoprotein complexes, validated experimentally through SHAPE-seq, electron microscopy, and crystallography. This work extends protein design principles to nucleic acids, enabling creation of diverse biomolecular architectures.\n2. Background: The core scientific problem addressed is the lack of robust methods for de novo design of nucleic acid tertiary structures and protein-nucleic acid complexes. While significant advances have been made in protein design, nucleic acid design has been limited to three main approaches: (1) structure-independent aptamer generation, (2) secondary structure-based design without 3D geometry consideration, and (3) geometrically constrained origami methods that rely on rigid assumptions. Prior challenges included inability to capture native-like RNA complexity (multi-angled junctions, bulges, bent helices), limited structural diversity in generated designs, and absence of experimental validation for computational approaches.\n3. Research Methodology: The technical roadmap involves a two-step process:\nBackbone generation using RFDpoly, an extension of RFdiffusion that:\nDenoises frame rotations and translations while predicting torsion angles Uses polymer-class conditioning (RNA/DNA/protein) through RoseTTAfold’s 1D track Incorporates base-pair conditioning through 2D templates for secondary structure control Handles multi-polymer generation with symmetric noise propagation Sequence design using either:\nNA-MPNN (nucleic acid version of ProteinMPNN) followed by PyRosetta repacking Autoregressive sequence-structure co-design during denoising The authors validated designs through:\nSHAPE-seq for secondary structure validation Negative stain and cryo-EM for tertiary structure characterization Crystallography for atomic-level validation Yeast display binding assays for protein-DNA interactions 4. Innovations: Key innovations include:\nGeneralized biopolymer design: First framework capable of designing RNA, DNA, and protein structures within a unified architecture Advanced conditioning: Base-pair templating with explicit control over pairing patterns, orientations, and pseudoknot topologies Full-atom generation: Torsion angle prediction enabling complete backbone construction without post-processing Hierarchical design: 2D motif templating allowing scaffolding of pre-characterized components into larger assemblies Experimental validation: Comprehensive validation across multiple techniques demonstrating physical accuracy 5. Applications: The findings enable numerous applications in drug discovery and biological research:\nRNA therapeutics: Design of stable RNA structures for siRNA, mRNA vaccines, and RNA-based therapeutics Biosensors: Creation of RNA-based sensors and riboswitches for diagnostic applications Gene regulation: Design of synthetic RNA regulators for controlling gene expression Nanotechnology: Construction of complex nucleoprotein assemblies for nanoscale devices Structural biology: Generation of novel RNA folds for studying structure-function relationships Specific examples from the paper include:\nDesigned RNA pseudocycles with novel folds validated by cryo-EM Protein-DNA complexes with nanomolar binding affinity Successful participation in Eterna OpenKnot challenges with improved folding over natural sequences 6. Limitations \u0026 Future Work: The authors acknowledge several limitations:\nPrediction reliability: Need for more reliable tertiary structure prediction methods for protein-nucleic acid assemblies Interface design: Limited capability for designing compact, partner-specific protein-RNA interfaces Chemical diversity: Lack of incorporation of noncanonical nucleotides and post-synthetic modifications Dataset size: Relatively small training dataset of experimentally determined RNA structures Future directions suggested:\nDevelopment of RNA-centric scaffolds for hierarchical assembly Incorporation of small-molecule ligands and chemical modifications Expansion to more diverse nucleic acid geometries and functions Integration with experimental characterization pipelines 7. Jargon Breakdown: Diffusion models: Generative AI approach that learns to denoise structures from random noise. Important for creating diverse, novel structures. Example: RFDpoly starts from random noise and gradually builds structured RNA backbones.\nBase-pair templating: Method to specify desired base-pairing patterns during generation. Important for controlling secondary and tertiary structure. Example: Providing dot-bracket notation to generate specific pseudoknot topologies.\nSHAPE-seq: Selective 2’-hydroxyl acylation analyzed by primer extension sequencing. Important for experimental validation of RNA secondary structure. Example: Measuring nucleotide flexibility to distinguish paired vs. unpaired regions.\nMotif scaffolding: Approach to incorporate known structural motifs into larger designs. Important for hierarchical design and reusing validated components. Example: Embedding DNA-binding proteins into larger nucleoprotein assemblies.\nTM-score: Metric for measuring structural similarity (0-1 scale). Important for assessing design quality. Example: Comparing designed structures to predicted folds with TM-score \u003e0.5 indicating good agreement.\n8. Connections: This paper represents a transformative capability rather than an incremental improvement in AIDD. It bridges two previously separate fields: protein design and nucleic acid design, enabling truly integrated biomolecular design. The work extends the success of diffusion-based protein design (RFdiffusion) to nucleic acids, creating the first generalized framework for multi-polymer design. This enables entirely new classes of biomolecules that were previously inaccessible to computational design, particularly complex RNA structures and protein-nucleic acid hybrids with precise geometric control.\nThe method presented in this paper has been open-sourced. The authors state that code and weights for RFDpoly will be made available on GitHub at the time of publication, along with tutorial notebooks for all design campaigns described.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "De Novo Design",
      "RNA Design",
      "Diffusion Models",
      "Nucleic Acid-Protein Complexes",
      "Generative AI"
    ],
    "title": "Diffusion Model RFDpoly Enables De Novo RNA and Nucleoprotein Design",
    "uri": "/blog/20251006/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Diffusion Models",
    "uri": "/tags/diffusion-models/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Nucleic Acid-Protein Complexes",
    "uri": "/tags/nucleic-acid-protein-complexes/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: RNA Design",
    "uri": "/tags/rna-design/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Antibody Engineering",
    "uri": "/tags/antibody-engineering/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Fitness Landscape",
    "uri": "/tags/fitness-landscape/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary Paper Title: From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?\nJournal: arXiv preprint\nPublish Date: October 2, 2025\nDOI: arXiv:2510.01571v1\nResearch Groups: The Chinese University of Hong Kong, Peking University, Stanford University, University of Pennsylvania, Nanjing University, National University of Singapore, University of Illinois Urbana-Champaign, Toyota Technological Institute at Chicago\nCentral Hypothesis: The study investigates whether reinforcement learning (RL)-enhanced protein language models (PLMs) can transcend their pre-training limitations and identify implicit sequence-structure-function relationships not explicitly encoded in foundational datasets. The researchers hypothesized that RL’s effectiveness is governed by a three-factor interaction: task difficulty, reward model accuracy, and policy capacity.\n2. Innovations Key Technical Innovations:\nThree-Factor Framework: Introduced a novel conceptual framework where RL effectiveness depends on the interaction between task difficulty (ruggedness of fitness landscape), reward accuracy (signal-to-noise ratio), and policy capacity (model size and representational power) Unified Evaluation Protocol: Developed comprehensive evaluation metrics including Expansion-Shrinkage Ratio (ESR) to quantify knowledge gain/loss during RL training Multi-Algorithm Comparison: Systematically compared three RL algorithms (DPO, PPO, GRPO) across diverse protein design tasks Support Metric Analysis: Introduced shrinkage, expansion, and preservation metrics to analyze how RL changes model capabilities Conceptual Innovations:\nBeyond Supervised Learning: Demonstrated that RL enables exploration beyond interpolation within existing sequence-function mappings Task-Dependent RL Efficacy: Showed that RL gains scale when rewards are accurate, policies have sufficient capacity, and tasks present headroom beyond supervised learning Exploration-Exploitation Tradeoff: Provided quantitative evidence of RL’s tendency to focus on high-reward regions at the cost of diversity 3. Applications Drug Discovery Applications:\nAntimicrobial Peptide Design: RL-enhanced models can discover novel AMPs with lower minimum inhibitory concentration (MIC) values, potentially leading to new antibiotics Antibody Optimization: Improved antibody binding affinity through targeted mutations in CDR regions, enabling development of more effective therapeutic antibodies Kinase Engineering: Optimization of enzyme activity for industrial and therapeutic applications through multi-step mutation strategies Biological Research Applications:\nProtein Inverse Folding: More efficient generation of sequences that fold into target structures, accelerating protein design experiments Fitness Landscape Exploration: Systematic exploration of protein sequence spaces to identify functional regions not accessible through supervised learning alone Multi-objective Optimization: Simultaneous optimization of multiple protein properties (e.g., stability, activity, specificity) through reward function design Specific Examples:\nGRPO algorithm discovered AMPs with several-fold higher activity than wild-type RL models achieved pass@k of 1.0 for antibody H3 and L1 sites, indicating perfect sampling efficiency Generated kinase variants with peak fitness scores of 133 compared to 70 for base models 4. Limitations \u0026 Future Work Acknowledged Limitations:\nDiversity Reduction: RL training often reduces sequence diversity as models focus on high-reward regions Reward Model Accuracy: Current reward models have limited accuracy (e.g., Spearman correlation of 0.47 for antibody binding affinity) Policy Capacity Constraints: Suboptimal policy model initialization limits exploration capabilities Task-Specific Challenges: Difficult tasks like antibody H1 and L3 optimization showed limited improvement (convergence to 0.67 pass@k) Future Directions:\nExtended Architectures: Apply framework to Diffusion/Flow Matching models and protein structure-sequence co-design Additional RL Algorithms: Explore Monte Carlo Tree Search (MCTS) and other RL approaches Improved Reward Models: Develop more accurate biological reward functions through better experimental integration Capacity Scaling: Investigate larger policy models to enhance exploration capabilities Real-time Experimental Integration: Incorporate experimental feedback directly into RL loops 5. Jargon Breakdown Protein Language Models (PLMs): AI models trained on protein sequences that learn patterns and relationships in protein data, similar to how ChatGPT understands human language but for proteins.\nReinforcement Learning (RL): A type of machine learning where an AI “agent” learns by trial and error, receiving “rewards” for good actions and “penalties” for bad ones, gradually improving its strategy.\nDirect Preference Optimization (DPO): A method that learns from examples of “good” and “bad” protein sequences without needing explicit scoring, like learning from before/after examples.\nPass@k Metric: Measures how often a model generates at least one good solution in k attempts - higher values mean better efficiency at finding working designs.\nFitness Landscape: A concept imagining protein sequences as a mountainous terrain where “higher” points represent better protein functions, and the challenge is finding the highest peaks.\nExpansion-Shrinkage Ratio (ESR): A score showing whether the model is learning new capabilities (ESR \u003e 1) or forgetting existing ones (ESR \u003c 1) during training.\nTM-Score: A measure of how similar a predicted protein structure is to the target structure, with higher scores indicating better matches.\n6. Connections Relationship to AIDD Field: This research represents a foundational advancement rather than an incremental improvement in AI-driven drug discovery (AIDD). It provides:\nNew Capabilities Enabled:\nSystematic RL Framework: Offers the first principled understanding of when and why RL works for protein design Quantitative Guidance: Provides practical metrics (ESR, support analysis) for evaluating RL effectiveness Exploration Beyond Training Data: Enables discovery of novel protein sequences not accessible through supervised learning alone Broader Impact:\nBridges NLP and Biology: Applies insights from language model RL fine-tuning to biological sequences Standardizes Evaluation: Introduces consistent metrics for comparing different RL approaches Informs Resource Allocation: Guides researchers on whether to prioritize reward model improvement, policy scaling, or algorithm selection Position in AIDD Landscape: This work establishes RL as a necessary complement to supervised learning in protein design, particularly for tasks requiring exploration beyond existing data. It moves the field from ad-hoc RL applications to a principled understanding of reinforcement learning’s capabilities and limitations in biological sequence design.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "Reinforcement Learning",
      "Protein Language Models",
      "Antibody Engineering",
      "De Novo Design",
      "Fitness Landscape"
    ],
    "title": "How Reinforcement Learning Unlocks Protein Design Potential",
    "uri": "/blog/20251005/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Reinforcement Learning",
    "uri": "/tags/reinforcement-learning/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Tags",
    "content": "",
    "description": "",
    "tags": [],
    "title": "Tag :: Protein Language Model",
    "uri": "/tags/protein-language-model/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary A trimodal protein language model enables advanced protein searches. Nat Biotechnol. Published online October 2, 2025. doi:10.1038/s41587-025-02836-0\nResearch Group: Westlake University, Hong Kong University of Science and Technology, and independent researchers\nCentral Hypothesis/Goal: The researchers hypothesized that unifying protein sequence, structure, and natural language function descriptions into a single trimodal language model through contrastive learning would enable comprehensive protein searches across and within modalities, overcoming limitations of traditional single-modality tools and providing more accurate functional predictions.\n2. Innovations Technical Innovations:\nFirst trimodal architecture simultaneously processing sequence (via ESM-2), structure (via Foldseek tokenization + BERT), and natural language function (via PubMedBERT) Contrastive learning framework with eight loss functions (six intermodal alignment + two masked language modeling) Massive training dataset of ~40 million protein-text pairs (10× larger than previous models) Maximum inner-product search (MIPS) algorithm enabling billion-scale database searches in seconds Conceptual Innovations:\nMoves beyond homology-based searching to identify functionally similar proteins regardless of evolutionary relationship Enables natural language queries of protein databases (e.g., “find proteins that bind zinc ions”) Supports nine distinct search modalities (sequence↔structure, sequence↔function, structure↔function) Global representation learning overcomes local similarity constraints of traditional alignment tools 3. Applications Drug Discovery:\nIdentifying novel enzyme variants for therapeutic applications (e.g., discovering improved uracil DNA glycosylase variants for base editing) Finding functionally analogous proteins across species for drug target identification Rapid screening of metagenomic databases for novel bioactive compounds Biological Research:\nAnnotating the ~30% of UniProt proteins currently without functional annotations Identifying convergent evolution cases where different sequences/structures perform similar functions Generating hypotheses for experimental validation (as demonstrated with UDG variant discovery) Supporting protein engineering by finding functional templates for AI-designed sequences Specific Example: Researchers used ProTrek to identify novel uracil DNA glycosylase variants that showed higher editing efficiency and lower indel frequencies than existing thymine base editors (TSBE3EK and gTBE) when fused with spCas9n.\n4. Limitations \u0026 Future Work Acknowledged Limitations:\nUnderrepresentation of some protein families may limit fine-grained predictions Less sensitive to subtle sequence variations (similar to AlphaFold2 limitation) Cannot precisely predict specific quantitative values (e.g., fluorescence wavelengths, stability) without specialized fine-tuning Performance on de novo designed proteins may be limited due to training exclusively on natural proteins Future Directions:\nExpand to encompass entire global protein data (targeting 10 billion protein search capacity) Develop specialized versions for quantitative prediction tasks through fine-tuning Integrate with protein design pipelines for inverse folding tasks Enhance multimodal capabilities with additional data types (e.g., expression, interaction data) 5. Jargon Breakdown Trimodal Language Model: An AI system that can understand and process three different types of information (in this case: protein sequences, 3D structures, and text descriptions) in a unified way.\nContrastive Learning: A training technique where the model learns to bring similar things closer together and push different things apart in its internal representation space.\nMaximum Inner-Product Search (MIPS): A fast algorithm for finding the most similar items in huge databases by calculating mathematical similarities between their numerical representations.\nConvergent Evolution: When different proteins evolve independently to perform similar functions, despite having different sequences and structures.\nHomology-based Searching: The traditional method of finding similar proteins by looking for evolutionary relationships and sequence similarities.\n3Di Sequences: A way of representing protein 3D structures as text-like sequences that can be processed by language models.\n6. Connections Relation to AIDD: ProTrek represents a significant advancement in AI-driven drug discovery by enabling functional protein searching at unprecedented scale and cross-modal flexibility. It bridges the gap between traditional bioinformatics tools and modern natural language processing.\nCapability Assessment: This is not merely an incremental improvement but enables fundamentally new capabilities:\nNatural language querying of protein databases Identification of functionally similar proteins without sequence/structure homology Unified search across sequence, structure, and function modalities Rapid screening of billion-scale protein databases The model serves as both a specialized tool for protein discovery and a general-purpose foundation for downstream AIDD applications, potentially accelerating target identification, lead optimization, and protein engineering pipelines.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "Protein Language Model"
    ],
    "title": "ProTrek: Trimodal AI Unlocks Advanced Protein Discovery",
    "uri": "/blog/20251004/index.html"
  },
  {
    "breadcrumb": "Learn Latest AIDD \u003e Blogs",
    "content": "1. Summary Paper Title: De novo design of phospho-tyrosine peptide binders\nJournal: bioRxiv (preprint)\nPublish Date: September 30, 2025\nDOI: https://doi.org/10.1101/2025.09.29.678898\nResearch Group/Institution: Institute for Protein Design, University of Washington (Baker Lab)\nCentral Hypothesis/Goal: The researchers hypothesized that their previously developed RoseTTAFold Diffusion 2 (RFD2) framework could be extended to design protein binders that specifically recognize phosphorylated tyrosine (pY) residues in unstructured peptide regions, addressing a major gap in our ability to probe phosphorylation-dependent signaling pathways.\n2. Innovations Key Technical Innovations:\nDevelopment of RFD2 for Molecular Interfaces (RFD2-MI): A specialized version of RFD2 trained on interface-focused datasets with enhanced conditioning capabilities 1D feature conditioning: Incorporation of per-residue features (hotspot masks, secondary structure, solvent accessibility) that guide interface formation during diffusion All-atom diffusion framework: Simultaneous generation of binder backbone and target peptide coordinates with atomic precision Integration with Logos pipeline: Combined approach for designing binders to both structured and disordered regions Conceptual Innovations:\nFirst general framework for designing binders to post-translationally modified proteins (specifically phosphorylated targets) Ability to design specificity for both phosphorylation state AND flanking sequence context (dual specificity) Demonstration that de novo designed proteins can achieve specificity rivaling or exceeding natural binding domains (SH2 domains) 3. Applications Real-World Applications:\nCancer Research \u0026 Therapeutics:\nTargeted inhibition of oncogenic signaling: Designed binders for EGFR pY1068 and pY1173 could disrupt growth factor signaling in cancers Immune modulation: CD3ε pY188 binders could potentially modulate T-cell activation for immunotherapy applications Diabetes Research:\nINSR pY1361 binders could help study insulin receptor signaling dynamics and develop new diabetes therapeutics Basic Research Tools:\nPhosphorylation-specific biosensors for live-cell imaging of signaling events Precision tools for mapping phosphorylation dynamics in specific pathways Reagents that distinguish between closely related phosphosites (overcoming antibody limitations) Drug Discovery:\nStarting points for developing small molecule inhibitors targeting phosphorylation-dependent interactions Modular components for PROTACs or other targeted degradation approaches 4. Limitations \u0026 Future Work Acknowledged Limitations:\nLow success rates (\u003c0.1% of designs were functional binders) Modest binding affinities (best Kd ~577 nM, most in micromolar range) Greater challenge achieving phosphorylation specificity versus sequence specificity Computational expense of the design pipeline Suggested Future Directions:\nOptimize phosphate interaction design to improve affinity and specificity Extend approach to other PTMs (methylation, acetylation, glycosylation) Incorporate multi-modal training data (chemical, structural, dynamic information) Improve success rates through better modeling of desolvation penalties Develop binders that function inside living cells Apply to broader range of therapeutic targets 5. Jargon Breakdown Phosphorylation: A chemical modification where a phosphate group is added to proteins (often to tyrosine, serine, or threonine residues), acting like a molecular switch that turns proteins on/off.\nDe novo design: Creating entirely new protein structures from scratch (not based on existing natural proteins).\nDiffusion model: A type of AI that learns to generate structures by reversing a process of adding noise (similar to how AI image generators work, but for 3D molecular structures).\nPost-translational modification (PTM): Chemical changes to proteins after they’re made by the cell, including phosphorylation, methylation, acetylation, etc.\nHotspot mask: A computational guide that tells the AI which parts of the target are most important for binding.\nBiolayer interferometry (BLI): A technique that measures how strongly two molecules bind together by detecting changes in light interference patterns.\nKd (Dissociation constant): A measure of binding strength - lower numbers mean tighter binding (nM is better than μM).\n6. Connections to AIDD Relationship to AIDD Field: This work represents a significant capability expansion rather than an incremental improvement. While previous AI-driven drug discovery (AIDD) methods could design binders to unmodified proteins, this is the first general approach for designing binders to post-translationally modified targets.\nNew Capabilities Enabled:\nAccess to “undruggable” targets: Many phosphorylation sites occur in disordered regions that lack structured pockets for conventional drug binding Precision targeting: Ability to distinguish between different phosphorylation states of the same protein Novel scaffold generation: Not limited to antibody architectures or natural binding domains Broader Impact: This work bridges the gap between structure-based drug design and PTM biology, enabling systematic targeting of modified protein states that are critical in disease but previously difficult to address. It demonstrates how AI methods can tackle challenges that have resisted conventional approaches, potentially opening up new target classes for therapeutic intervention.",
    "description": "daily summary of latest AIDD literature",
    "tags": [
      "Antibody",
      "De Novo Design"
    ],
    "title": "AI Designs First Phospho-Specific Protein Binders",
    "uri": "/blog/20251003/index.html"
  }
]
