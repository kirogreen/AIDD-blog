<!DOCTYPE html>
<html lang="zh-cn" dir="ltr" itemscope itemtype="http://schema.org/Article" data-r-output-format="html">
  <head><script src="/livereload.js?mindelay=10&amp;v=2&amp;port=1313&amp;path=livereload" data-no-instant defer></script>
    <meta charset="utf-8">
    <meta name="viewport" content="height=device-height, width=device-width, initial-scale=1.0, minimum-scale=1.0">
    <meta name="generator" content="Hugo 0.150.1">
    <meta name="generator" content="Relearn 8.0.0+6f266e9b46dc2a685d18950a0f32c37f74e6c50d">
    <meta name="description" content="daily summary of latest AIDD literature">
    <meta name="author" content="">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="What Protein Language Models Learn During RL Fine-Tuning :: Learn Latest AIDD">
    <meta name="twitter:description" content="daily summary of latest AIDD literature">
    <meta property="og:url" content="http://localhost:1313/blog/20251006/index.html">
    <meta property="og:site_name" content="Learn Latest AIDD">
    <meta property="og:title" content="What Protein Language Models Learn During RL Fine-Tuning :: Learn Latest AIDD">
    <meta property="og:description" content="daily summary of latest AIDD literature">
    <meta property="og:locale" content="zh_cn">
    <meta property="og:type" content="article">
    <meta property="article:section" content="Blogs">
    <meta property="article:published_time" content="2025-10-06T22:22:42+08:00">
    <meta property="article:modified_time" content="2025-10-06T22:22:42+08:00">
    <meta property="article:tag" content="Reinforcement Learning">
    <meta property="article:tag" content="Protein Language Models">
    <meta property="article:tag" content="Antibody Engineering">
    <meta property="article:tag" content="De Novo Design">
    <meta property="article:tag" content="Direct Preference Optimization">
    <meta itemprop="name" content="What Protein Language Models Learn During RL Fine-Tuning :: Learn Latest AIDD">
    <meta itemprop="description" content="daily summary of latest AIDD literature">
    <meta itemprop="datePublished" content="2025-10-06T22:22:42+08:00">
    <meta itemprop="dateModified" content="2025-10-06T22:22:42+08:00">
    <meta itemprop="wordCount" content="835">
    <meta itemprop="keywords" content="Reinforcement Learning,Protein Language Models,Antibody Engineering,De Novo Design,Direct Preference Optimization">
    <title>What Protein Language Models Learn During RL Fine-Tuning :: Learn Latest AIDD</title>
    <link href="/css/auto-complete/auto-complete.min.css?1759763412" rel="stylesheet">
    <script src="/js/auto-complete/auto-complete.min.js?1759763412" defer></script>
    <script src="/js/search-lunr.js?1759763412" defer></script>
    <script src="/js/search.js?1759763412" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.index_js_url="/searchindex.en.js?1759763412";
    </script>
    <script src="/js/lunr/lunr.min.js?1759763412" defer></script>
    <script src="/js/lunr/lunr.stemmer.support.min.js?1759763412" defer></script>
    <script src="/js/lunr/lunr.multi.min.js?1759763412" defer></script>
    <script src="/js/lunr/lunr.zh.min.js?1759763412" defer></script>
    <script>
      window.relearn = window.relearn || {};
      window.relearn.contentLangs=['zh'];
    </script>
    <link href="/fonts/fontawesome/css/fontawesome-all.min.css?1759763412" rel="stylesheet" media="print" onload="this.media='all';this.onload=null;"><noscript><link href="/fonts/fontawesome/css/fontawesome-all.min.css?1759763412" rel="stylesheet"></noscript>
    <link href="/css/perfect-scrollbar/perfect-scrollbar.min.css?1759763412" rel="stylesheet">
    <link href="/css/theme.css?1759763412" rel="stylesheet">
    <link href="/css/format-html.css?1759763412" rel="stylesheet" id="R-format-style">
    <script>
      window.relearn = window.relearn || {};
      // configuration
      window.relearn.min = ``;
      window.relearn.path='\/blog\/20251006\/index.html';
      window.relearn.relBasePath='..\/..';
      window.relearn.relBaseUri='..\/..';
      window.relearn.absBaseUri='http:\/\/localhost:1313';
      window.relearn.disableAnchorCopy=false;
      window.relearn.disableAnchorScrolling=false;
      window.relearn.disableInlineCopyToClipboard=false;
      window.relearn.enableBlockCodeWrap=true;
      // legal
      window.relearn.getItem = (s,n) => {return s.getItem(n)};
      window.relearn.setItem = (s,n,v) => {return s.setItem(n,v)};
      window.relearn.removeItem = (s,n) => {return s.removeItem(n)};
      // translations
      window.T_Copy_to_clipboard = `Copy to clipboard`;
      window.T_Copied_to_clipboard = `Copied to clipboard!`;
      window.T_Copy_link_to_clipboard = `Copy link to clipboard`;
      window.T_Link_copied_to_clipboard = `Copied link to clipboard!`;
      window.T_Reset_view = `Reset view`;
      window.T_View_reset = `View reset!`;
      window.T_No_results_found = `No results found for "{0}"`;
      window.T_N_results_found = `{1} results found for "{0}"`;
      // variant stuff
      window.relearn.themevariants = [ 'auto' ];
      window.relearn.customvariantname = "my-custom-variant";
      window.relearn.changeVariant = function(variant) {
        var oldVariant = document.documentElement.dataset.rThemeVariant;
        window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        document.documentElement.dataset.rThemeVariant = variant;
        if (oldVariant != variant) {
          document.dispatchEvent( new CustomEvent('themeVariantLoaded', { detail: { variant, oldVariant } }) );
          window.relearn.markVariant();
        }
      }
      window.relearn.markVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant");
        document.querySelectorAll(".R-variantswitcher select").forEach((select) => {select.value = variant;});
      }
      window.relearn.initVariant = function() {
        var variant = window.relearn.getItem(window.localStorage, window.relearn.absBaseUri + "/variant") ?? "";
        if( variant == window.relearn.customvariantname ){
        }else if( !variant || !window.relearn.themevariants.includes(variant) ){
          variant = window.relearn.themevariants[0];
          window.relearn.setItem(window.localStorage, window.relearn.absBaseUri + "/variant", variant);
        }
        document.documentElement.dataset.rThemeVariant = variant;
      }
      window.relearn.initVariant();
      window.relearn.markVariant();
    </script>
  </head>
  <body class="mobile-support html" data-url="/blog/20251006/index.html">
    <div id="R-body" class="default-animation">
      <div id="R-body-overlay"></div>
      <nav id="R-topbar">
        <div class="topbar-wrapper">
          <div class="topbar-sidebar-divider"></div>
          <div class="topbar-area topbar-area-start" data-area="start">
            <div class="topbar-button topbar-button-sidebar" data-content-empty="disable" data-width-s="show" data-width-m="hide" data-width-l="hide"><button class="topbar-control" onclick="toggleNav()" type="button" title="Menu (CTRL&#43;ALT&#43;n)"><i class="fa-fw fas fa-bars"></i></button>
            </div>
            <div class="topbar-button topbar-button-toc" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="Table of Contents (CTRL&#43;ALT&#43;t)"><i class="fa-fw fas fa-list-alt"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
<nav class="TableOfContents">
  <ul>
    <li><a href="#1-summary">1. Summary</a></li>
    <li><a href="#2-background">2. Background</a></li>
    <li><a href="#3-research-methodology">3. Research Methodology</a></li>
    <li><a href="#4-innovations">4. Innovations</a></li>
    <li><a href="#5-applications">5. Applications</a></li>
    <li><a href="#6-limitations--future-work">6. Limitations &amp; Future Work</a></li>
    <li><a href="#7-jargon-breakdown">7. Jargon Breakdown</a></li>
    <li><a href="#8-connections">8. Connections</a></li>
    <li><a href="#9-note">9. Note</a></li>
  </ul>
</nav>
                </div>
              </div>
            </div>
          </div>
          <ol class="topbar-breadcrumbs breadcrumbs highlightable" itemscope itemtype="http://schema.org/BreadcrumbList"><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/index.html"><span itemprop="name">Learn Latest AIDD</span></a><meta itemprop="position" content="1">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><a itemprop="item" href="/blog/index.html"><span itemprop="name">Blogs</span></a><meta itemprop="position" content="2">&nbsp;>&nbsp;</li><li itemscope itemtype="https://schema.org/ListItem" itemprop="itemListElement" class=""><span itemprop="name">What Protein Language Models Learn During RL Fine-Tuning</span><meta itemprop="position" content="3"></li>
          </ol>
          <div class="topbar-area topbar-area-end" data-area="end">
            <div class="topbar-button topbar-button-prev" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/blog/index.html" title="Blogs (🡐)"><i class="fa-fw fas fa-chevron-left"></i></a>
            </div>
            <div class="topbar-button topbar-button-next" data-content-empty="disable" data-width-s="show" data-width-m="show" data-width-l="show"><a class="topbar-control" href="/blog/20251005/index.html" title="How Reinforcement Learning Unlocks Protein Design Potential (🡒)"><i class="fa-fw fas fa-chevron-right"></i></a>
            </div>
            <div class="topbar-button topbar-button-more" data-content-empty="hide" data-width-s="show" data-width-m="show" data-width-l="show"><button class="topbar-control" onclick="toggleTopbarFlyout(this)" type="button" title="More"><i class="fa-fw fas fa-ellipsis-v"></i></button>
              <div class="topbar-content">
                <div class="topbar-content-wrapper">
                  <div class="topbar-area topbar-area-more" data-area="more">
                  </div>
                </div>
              </div>
            </div>
          </div>
        </div>
      </nav>
      <div id="R-main-overlay"></div>
      <main id="R-body-inner" class="highlightable blog" tabindex="-1">
        <div class="flex-block-wrapper">
<article class="default">
  <header class="headline">
<div class="R-taxonomy taxonomy-tags cstyle tags" title="Tags" style="--VARIABLE-TAGS-BG-color: var(--INTERNAL-TAG-BG-color);">
  <ul>
    <li><a class="term-link" href="/tags/antibody-engineering/index.html">Antibody Engineering</a></li>
    <li><a class="term-link" href="/tags/de-novo-design/index.html">De Novo Design</a></li>
    <li><a class="term-link" href="/tags/direct-preference-optimization/index.html">Direct Preference Optimization</a></li>
    <li><a class="term-link" href="/tags/protein-language-models/index.html">Protein Language Models</a></li>
    <li><a class="term-link" href="/tags/reinforcement-learning/index.html">Reinforcement Learning</a></li>
  </ul>
</div>
  </header>

<h1 id="what-protein-language-models-learn-during-rl-fine-tuning">What Protein Language Models Learn During RL Fine-Tuning</h1>

<h2 id="1-summary">1. Summary</h2>
<p><strong>Original Title:</strong> From Supervision to Exploration: What Does Protein Language Model Learn During Reinforcement Learning?
<strong>Journal:</strong> arXiv preprint
<strong>Publication Date:</strong> October 2, 2025
<strong>DOI:</strong> arXiv:2510.01571v1
<strong>Primary Research Group/Institution:</strong> Multi-institutional collaboration led by The Chinese University of Hong Kong, Peking University, and Stanford University.</p>
<p>This study systematically investigates whether reinforcement learning (RL) can help protein language models (PLMs) discover novel sequence-function relationships beyond their pre-training data. Through experiments across four protein design domains (antimicrobial peptide design, kinase optimization, antibody engineering, and inverse folding), the authors demonstrate that RL improves sampling efficiency but its effectiveness depends on a three-factor interaction: task difficulty, reward model accuracy, and policy capacity.</p>
<h2 id="2-background">2. Background</h2>
<p>The core scientific problem addresses the fundamental limitations of supervised learning approaches in protein design. Traditional methods struggle with: 1) optimizing complex non-differentiable biological objectives, 2) exploring beyond existing sequence-function mappings, and 3) integrating multi-objective criteria or experimental feedback. While protein language models have shown remarkable success through pre-training, they remain constrained by their training distributions. Reinforcement learning has demonstrated transformative potential in NLP by enabling models to discover emergent capabilities, but its capacity to unlock latent functional patterns in protein space remained underexplored.</p>
<h2 id="3-research-methodology">3. Research Methodology</h2>
<p>The authors employed a comprehensive evaluation framework across four biological systems:</p>
<ol>
<li><strong>Protein Inverse Folding</strong>: Used InstructPLM-7B as policy model with TM-Score as reward, implementing DPO with regularization</li>
<li><strong>Antimicrobial Peptide Design</strong>: Employed Amphion-SFT with ApexMIC reward predictor, testing DPO, PPO, and GRPO algorithms</li>
<li><strong>Kinase Mutation</strong>: Utilized ESM-2 architecture for multi-step mutations with experimental fitness as reward</li>
<li><strong>Antibody Optimization</strong>: Developed improved ProtAttBA model for binding affinity prediction, using PPO and GRPO</li>
</ol>
<p>The technical approach involved:</p>
<ul>
<li>Systematic comparison of RL algorithms (DPO, PPO, GRPO)</li>
<li>Introduction of Expansion-Shrinkage Ratio (ESR) metric to quantify knowledge gain/loss</li>
<li>Comprehensive evaluation using Pass@k metrics and biological plausibility measures</li>
<li>Latent space analysis through UMAP visualizations</li>
</ul>
<h2 id="4-innovations">4. Innovations</h2>
<p><strong>Key innovations compared to previous state-of-the-art:</strong></p>
<ol>
<li><strong>Three-Factor Framework</strong>: First principled framework identifying that RL effectiveness depends on task difficulty, reward accuracy, and policy capacity interaction</li>
<li><strong>Expansion-Shrinkage Ratio (ESR)</strong>: Novel metric to quantify the trade-off between discovering new solutions and forgetting previous knowledge during RL fine-tuning</li>
<li><strong>Systematic Cross-Domain Evaluation</strong>: First comprehensive study comparing RL effects across multiple protein design tasks using consistent evaluation metrics</li>
<li><strong>Improved Reward Modeling</strong>: Enhanced antibody binding affinity prediction with combined regression and MLM objectives</li>
<li><strong>Task-Specific Algorithm Guidance</strong>: Evidence-based recommendations for which RL algorithms work best for different protein design challenges</li>
</ol>
<h2 id="5-applications">5. Applications</h2>
<p><strong>Real-world applications in drug discovery and biological research:</strong></p>
<ol>
<li><strong>Accelerated Antibody Optimization</strong>: More efficient generation of high-affinity antibody variants for therapeutic development, particularly for cancer and infectious diseases</li>
<li><strong>Novel Antimicrobial Peptide Discovery</strong>: Design of more potent AMPs to address antibiotic resistance crisis</li>
<li><strong>Enzyme Engineering</strong>: Optimization of kinase and other enzyme properties for industrial biocatalysis and therapeutic applications</li>
<li><strong>De Novo Protein Design</strong>: Improved inverse folding for creating proteins with novel functions not found in nature</li>
<li><strong>Experimental-Guided Design</strong>: Framework for incorporating experimental feedback into computational design pipelines</li>
</ol>
<h2 id="6-limitations--future-work">6. Limitations &amp; Future Work</h2>
<p><strong>Acknowledged limitations:</strong></p>
<ul>
<li>RL often reduces diversity and novelty while improving specificity</li>
<li>Performance heavily dependent on reward model accuracy (e.g., Spearman=0.47 for antibody task)</li>
<li>ESR &lt; 1.0 in many cases indicates net knowledge loss during fine-tuning</li>
<li>Computationally intensive requiring significant resources</li>
</ul>
<p><strong>Suggested future directions:</strong></p>
<ul>
<li>Extend to Diffusion/Flow Matching architectures beyond PLMs</li>
<li>Explore protein structure and sequence-structure co-design</li>
<li>Incorporate additional RL algorithms (e.g., MCTS)</li>
<li>Improve reward model accuracy and robustness</li>
<li>Develop better regularization techniques to maintain diversity</li>
</ul>
<h2 id="7-jargon-breakdown">7. Jargon Breakdown</h2>
<p><strong>Protein Language Models (PLMs):</strong> AI models trained on protein sequences to understand and generate biologically plausible proteins. Example: ESM-2 or ProtGPT2 that can predict protein function or generate novel sequences.</p>
<p><strong>Reinforcement Learning (RL):</strong> Machine learning approach where an agent learns to make decisions by receiving rewards or penalties. Example: Training a model to generate better antibodies by rewarding improved binding affinity.</p>
<p><strong>Direct Preference Optimization (DPO):</strong> RL technique that learns from preference pairs without explicit reward modeling. Example: Showing the model pairs of proteins where one has better activity and learning to prefer it.</p>
<p><strong>Pass@k:</strong> Evaluation metric measuring the probability of generating at least one successful sequence in k attempts. Example: Pass@100 = 0.8 means 80% chance of getting a good protein in 100 tries.</p>
<p><strong>TM-Score:</strong> Metric for assessing structural similarity between proteins (1.0 = perfect match). Example: Used to evaluate how well a generated sequence folds into the target structure.</p>
<h2 id="8-connections">8. Connections</h2>
<p>This paper provides a significant <strong>incremental improvement</strong> to the AIDD field by offering a principled framework for applying RL to protein design. It doesn&rsquo;t enable fundamentally new capabilities but provides crucial insights into how to effectively use existing RL techniques with PLMs. The research connects to broader AIDD by:</p>
<ul>
<li>Establishing guidelines for when and how to apply RL in protein design pipelines</li>
<li>Providing diagnostic tools (like ESR) to evaluate RL training effectiveness</li>
<li>Demonstrating the importance of reward model quality in biological applications</li>
<li>Offering practical guidance for resource allocation in RL-based protein engineering</li>
</ul>
<h2 id="9-note">9. Note</h2>
<p>The method presented in this paper has been open-sourced. Implementation is available at github (specific repository URL not provided in the document).</p>

  <footer class="footline">
              <i class='fa-fw fas fa-calendar'></i> Oct 6, 2025
<div class="R-taxonomy taxonomy-categories cstyle" title="Categories" style="--VARIABLE-TAGS-BG-color: var(--INTERNAL-TAG-BG-color);">
  <i class="fa-fw fas fa-layer-group"></i>
  <ul>
    <li><a class="term-link" href="/categories/literature-review/index.html">Literature Review</a></li>
  </ul>
</div>
  </footer>
</article>
        </div>
      </main>
    </div>
    <aside id="R-sidebar" class="default-animation">
      <div id="R-header-topbar" class="default-animation"></div>
      <div id="R-header-wrapper" class="default-animation">
        <div id="R-header" class="default-animation">
          <a id="R-logo" class="R-default" href="/index.html">
            <div class="logo-title">Learn Latest AIDD</div>
          </a>
        </div>
        <search><form action="/search/index.html" method="get">
          <div class="searchbox default-animation">
            <button class="search-detail" type="submit" title="Search (CTRL+ALT+f)"><i class="fas fa-search"></i></button>
            <label class="a11y-only" for="R-search-by">Search</label>
            <input data-search-input id="R-search-by" name="search-by" class="search-by" type="search" placeholder="Search...">
            <button class="search-clear" type="button" data-search-clear="" title="Clear search"><i class="fas fa-times" title="Clear search"></i></button>
          </div>
        </form></search>
      </div>
      <div id="R-homelinks" class="default-animation homelinks">
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-homelinks">
          <ul class="space collapsible-menu">
            <li class="" data-nav-url="/index.html"><a class="padding" href="/index.html"><i class="fa-fw fas fa-home"></i> Home</a></li>
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-headercontrols">
          <ul class="">
          </ul>
        </div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
      </div>
      <div id="R-content-wrapper" class="highlightable">
        <div class="R-sidebarmenu R-shortcutmenu-main">
          <ul class="enlarge morespace collapsible-menu">
            <li class="parent " data-nav-url="/blog/index.html"><a class="padding" href="/blog/index.html">Blogs</a><ul id="R-subsections-c061e150208a7ab43c1b0b723b79816b" class="collapsible-menu">
            <li class="active " data-nav-url="/blog/20251006/index.html"><a class="padding" href="/blog/20251006/index.html">What Protein Language Models Learn During RL Fine-Tuning</a></li>
            <li class="" data-nav-url="/blog/20251005/index.html"><a class="padding" href="/blog/20251005/index.html">How Reinforcement Learning Unlocks Protein Design Potential</a></li>
            <li class="" data-nav-url="/blog/20251004/index.html"><a class="padding" href="/blog/20251004/index.html">ProTrek: Trimodal AI Unlocks Advanced Protein Discovery</a></li>
            <li class="" data-nav-url="/blog/20251003/index.html"><a class="padding" href="/blog/20251003/index.html">AI Designs First Phospho-Specific Protein Binders</a></li></ul></li>
          </ul>
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-shortcuts">
          <ul class="space collapsible-menu">
          </ul>
        </div>
        <div id="R-footer-margin"></div>
        <div class="R-menu-divider default-animation">
          <hr class="padding">
        </div>
        <div class="R-sidebarmenu R-shortcutmenu-footercontrols">
          <ul class="">
          </ul>
        </div>
<div id="R-footer"><p>Built with <a href="https://github.com/McShelby/hugo-theme-relearn" title="love"><i class="fas fa-heart"></i></a> by <a href="https://gohugo.io/">Hugo</a></p></div>
      </div>
    </aside>
    <script src="/js/clipboard/clipboard.min.js?1759763412" defer></script>
    <script src="/js/perfect-scrollbar/perfect-scrollbar.min.js?1759763412" defer></script>
    <script src="/js/theme.js?1759763412" defer></script>
  </body>
</html>
